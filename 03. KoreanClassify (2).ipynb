{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 문서의 분류\n",
    "올리브영으로부터 크롤링한 향수 리뷰를 이용하여 분류 연습.\n",
    "향수 리뷰와 향수 이름을 학습해서 주어진 리뷰내용으로 어떤 향수에 대한 리뷰인지를 예측하고자 함.\n",
    "\n",
    "### data file 내용\n",
    "여러 향수에 대한 약 1000개의 리뷰\n",
    "csv 파일 안에 리뷰내용, 가격, 향수이름의 순으로 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('C:/Users/Seo/perfume7.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[0]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 973\n",
      "perfume of reivews: {'나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', 'Name', '클린 웜코튼 EDP 30ml (N) 기프트세트', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('perfume of reivews: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) #1827의 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['클', '림', '심플', '?', '향', '을', '구매', '하고', '샘플', '로', '온', '향', '을', '동생', '이', '맡아', '봤는데', '너무', '마음', '에', '들어', '해서', '선물', '로', '사줬습니다', '.', '호불호', '없이', '비누', '향', '좋아하시는', '분', '들이라면', '좋아할', '향', '이에요', '.', '여름', '보다는', '지금', '처럼', '추운', '계절', '에', '잘', '어울리는', '포근한', '비누', '향', '입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['림',\n",
       " '심플',\n",
       " '향',\n",
       " '구매',\n",
       " '샘플',\n",
       " '온',\n",
       " '향',\n",
       " '동생',\n",
       " '마음',\n",
       " '선물',\n",
       " '호불호',\n",
       " '비누',\n",
       " '향',\n",
       " '분',\n",
       " '향',\n",
       " '여름',\n",
       " '지금',\n",
       " '계절',\n",
       " '비누',\n",
       " '향']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text): # Twitter 형태소 분석기의 명사추출함수를 tokenizer 함수로 사용\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9039780521262003\n",
      "Test score 0.7049180327868853\n",
      "(729, 979)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 979개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정말 고민 엄청 많이 하다가 저번에 기획세트때 구매를 놓치고 계속 아쉬워하다가 이번에 올영세일하면서 살짝 추가 세일하길래 이때다 하고 쿠폰까지 알뜰하게 받아서 구매하게 되었는데 정말..왜 이제서야 구매했나 싶어요  정말 너무 제 취향의 항수여서 행복하네요ㅠㅠ 원래 밖에 잘 안 나가는데 이거 뿌리고 싶어서 나가고 싶을 정도에요ㅋㅋ  저는 중성적인 향을 좋아하는 편인데 이 향수는 약간 시원하면서 살짝 달달한 그런 느낌의 향수인데(설명 못하는 편) 데일리하게 사용하기에 좋고 패키지도 하얀색으로 깔끔하고 좋아요!( 대신 뚜껑을 닫을때 조금 힘주면서 닫아야합니다!)  내일 나갈일 있는데 이거 뿌리고 나가야지.. 요놈 덕분에 나갈때 신이나네요!!!너무 좋아!!!!!',\n",
       " '언니가 사용중인데, 스칠때마다 은은하게 나는 향이 좋아서 저는  언니꺼 하나 뺏고,  마침 지인이 생일이라 선물했습니다. 향이 너무 좋다고 좋아라네요~ 향수도 많이 가지고 있는데, 은은하게 내고 싶을때 사용하면 좋을꺼 같아요.. 지속력이 향수만큼은 아니라 가지고 다니면서 손 씻고 나서 조금씩 팔목에 바르면 좋을꺼 같아요.',\n",
       " '남여상관업이너무죠은향같아요.. 이걸죠아하게된동기가조금웃깃데ㅎㅎ 생각나서..구입해서..계속쓰게될꺼같네요ㅎㅎ',\n",
       " '과대 광고에 속은것 같아요 기내에서 무슨향이냐고 물어볼만큼 좋진 않던데  차라리 록시땅이 백만배 낫지',\n",
       " '향 너무 좋아요 남친이랑 같이 쓰고있어요 남녀 무관 다 사용가능',\n",
       " '매장에서 테스트 해보고 뿌린 후에 향이 너무 좋아 집에서도 생각나서 인터넷으로 바로 구매한 제품입니다. 향이 처음엔 강하게 느낄 수도 있는데 시간이 지날수록 은은하고 계속 맡고 싶은 향입니다. 지속력은 그리 오래가지는 않지만 그래도 다쓰면 또 구매하고 싶은 상품입니다',\n",
       " '처음 써보는 브랜드 향수라 고민하다가 송혜교가 쓴다고 추천 받아서 덜컥 사버렸던 향수입니다. 파우더리한 머스크 향기가 넘 매력있어요.',\n",
       " '향도 고급스럽고 시향해서 샀는데 문제는 지속력이 로션수준도 안된다는것.다른향수를 다시 사야할듯',\n",
       " '당첨자 발표가 나기 하루 전에 이미 택배가 도착했어요 ^^  시세이도에서 구매를 안했는데 택배가 온다는 알림에 뭘까 궁금해 하다가 택배를 받았어요 택배를 열어보고서야 테스터에 당첨됐구나! 싶었어요   향수는 작은데 택배상자가 너무 컸어요.. 재활용할 수 있는 종이박스와 포장재였지만 택배박스 크기를 줄였으면 하는 마음이 ㅜㅜ    나르시소의 커머셜 이미지를 보고 중성적인 향수일거라 예상했지만 처음 향수를 뿌리고 약간 당황했어요 남자친구에게서 맡을 수 있던 남자 스킨냄새? 같은게 났거든요   일어나고 얼마 지나지않아 향수를 사용해서 그런걸까 싶어서 박스랑 포장재 펴서 정리하고 다시 뿌려봤습니다 그래도 냄새가 ㅎㅎ   하지만 첫 향이 엄청 빨리 날아가더라구요 (향수의 지속력 자체도 길지 않은게 단점이에요..)  그리고 이어지는 은은한 머스크 향과 수수한 꽃향이 잔잔하게 퍼지는데 너무 좋아요 시세이도에 이렇게 좋은 향수도 있었구나 싶었어요 시세이도는 향수로 유명한 브랜드가 아니잖아요   저의 취향은 달달한 향수라 죄다 달달한 향 뿐이었는데 나르시소 쓰면서 취향이 바뀐거같아요 진짜 처음엔 당첨된거라지만 못쓰겠다 싶었는데.. 그냥 집에 있는 날에도 씻고 나와서 뿌리고 있어요 키우는 고양이들은 처음에 낯선지 향수 뿌리면 주변에 안오더니 2주가 지난 지금은 향수 뿌릴때도 주변에 있어요ㅋㅋ  뭔가 바꾸고 싶다 매일 똑같은 일상이 지겹다 싶으면 향수 바꾸는거 추천해요 내 일상을 바꿀순 없어도 향수만 바꿔도 기분이 달라지고 하루가 달라지더라구요   나르시소 끝까지 잘 쓸게요~',\n",
       " '선물 받은 사람이 매우 만족합니다!  향도 매우 좋아요! 깔끔한 향입니다-']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['클린 웜코튼 EDP 30ml (N) 기프트세트', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml',\n",
       "       '클린 웜코튼 EDP 30ml (N) 기프트세트', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml',\n",
       "       '클린 웜코튼 EDP 30ml (N) 기프트세트', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml',\n",
       "       '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '클린 웜코튼 EDP 30ml (N) 기프트세트',\n",
       "       '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '클린 웜코튼 EDP 30ml (N) 기프트세트'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml', '클린 웜코튼 EDP 30ml (N) 기프트세트', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml', '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '유즈 솔리드 퍼퓸 002 스테이포에버 30ml', '나르시소 로드리게즈 퓨어 머스크 포 허 EDP 30ml', '클린 웜코튼 EDP 30ml (N) 기프트세트']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 향수이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['클', '림', '심플', '?', '향', '을', '구매', '하고', '샘플', '로', '온', '향', '을', '동생', '이', '맡아', '봤는데', '너무', '마음', '에', '들어', '해서', '선물', '로', '사줬습니다', '.', '호불호', '없이', '비누', '향', '좋아하시는', '분', '들이라면', '좋아할', '향', '이에요', '.', '여름', '보다는', '지금', '처럼', '추운', '계절', '에', '잘', '어울리는', '포근한', '비누', '향', '입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사 외에도 모든 형태소를 포함\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9108367626886146\n",
      "Test score 0.7172131147540983\n",
      "(729, 2375)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 대신 모든 형태소를 사용\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#명사만 사용한 것에 비해 train score는 상승, test score도 상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('크다', 'Verb'), ('림', 'Noun'), ('심플', 'Noun'), ('?', 'Punctuation'), ('향', 'Noun'), ('을', 'Josa'), ('구매', 'Noun'), ('하고', 'Josa'), ('샘플', 'Noun'), ('로', 'Josa'), ('온', 'Noun'), ('향', 'Noun'), ('을', 'Josa'), ('동생', 'Noun'), ('이', 'Josa'), ('맡다', 'Verb'), ('보다', 'Verb'), ('너무', 'Adverb'), ('마음', 'Noun'), ('에', 'Josa'), ('들다', 'Verb'), ('하다', 'Verb'), ('선물', 'Noun'), ('로', 'Josa'), ('사주다', 'Verb'), ('.', 'Punctuation'), ('호불호', 'Noun'), ('없이', 'Adverb'), ('비누', 'Noun'), ('향', 'Noun'), ('좋아하다', 'Adjective'), ('분', 'Noun'), ('들이다', 'Verb'), ('좋아하다', 'Adjective'), ('향', 'Noun'), ('이에요', 'Josa'), ('.', 'Punctuation'), ('여름', 'Noun'), ('보다는', 'Josa'), ('지금', 'Noun'), ('처럼', 'Josa'), ('추다', 'Verb'), ('계절', 'Noun'), ('에', 'Josa'), ('자다', 'Verb'), ('어울리다', 'Verb'), ('포근하다', 'Adjective'), ('비누', 'Noun'), ('향', 'Noun'), ('이다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['크다', '림', '심플', '향', '구매', '샘플', '온', '향', '동생', '맡다', '보다', '마음', '들다', '하다', '선물', '사주다', '호불호', '비누', '향', '좋아하다', '분', '들이다', '좋아하다', '향', '여름', '지금', '추다', '계절', '자다', '어울리다', '포근하다', '비누', '향', '이다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9204389574759945\n",
      "Test score 0.7213114754098361\n",
      "(729, 1351)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 train score와 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9039780521262003\n",
      "Test score 0.7254098360655737\n",
      "(729, 1766)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.992\n",
      "Test set score: 0.697\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 많이 올라가는 현상이 벌어짐\n",
    "# test score가 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.759\n",
      "Test set score: 0.705\n",
      "Used features count: 106 out of 1766\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01272797 0.01535934 0.01391181 0.0119879  0.00981152 0.00938478\n",
      " 0.00888663 0.00824467 0.00785292 0.0076218  0.00739273 0.00718091\n",
      " 0.00698807 0.00690575 0.00665107 0.00638571 0.0063371  0.00617013\n",
      " 0.00601059 0.00594473 0.00576946 0.00568242 0.00562685 0.00559611\n",
      " 0.0053678  0.0053023  0.00526049 0.0051909  0.00509188 0.00504222\n",
      " 0.00502261 0.00492295 0.00487171 0.00482909 0.0046877  0.00467147\n",
      " 0.00460281 0.00454153 0.00450718 0.00444192 0.00440306 0.00436811\n",
      " 0.00426428 0.00424517 0.00421482 0.00418513 0.00414284 0.00407579\n",
      " 0.00404944 0.00398521 0.00395656 0.00393727 0.00388572 0.00378201\n",
      " 0.00376215 0.00375652 0.00370826 0.00369295 0.00365433 0.0036443\n",
      " 0.00358839 0.00355951 0.00351737 0.00348155 0.0034484  0.00344025\n",
      " 0.00342797 0.00337484 0.00336    0.00329511 0.00328196 0.00326446\n",
      " 0.00322843 0.00321604 0.00320984 0.00318434 0.00314877 0.00313846\n",
      " 0.00310071 0.00305728 0.00304596 0.00303976 0.00301643 0.00298961\n",
      " 0.00296337 0.00294752 0.00293947 0.00290358 0.00287307 0.00286844\n",
      " 0.00285676 0.00284776 0.00281711 0.00280154 0.0027861  0.00275059\n",
      " 0.00274401 0.00272449 0.00271168 0.00267294 0.00267071 0.00265147\n",
      " 0.00263802 0.00261756 0.00261038 0.00259963 0.00257074 0.00255749\n",
      " 0.00254662 0.00253039 0.00251351 0.00250455 0.00247922 0.00246995\n",
      " 0.00246399 0.00245564 0.00243156 0.00241736 0.00241361 0.00240068\n",
      " 0.00238053 0.00235818 0.00234213 0.00233622 0.00232787 0.00230956\n",
      " 0.00229563 0.002276   0.00226296 0.00225244 0.00223607 0.00223296\n",
      " 0.00220279 0.00220163 0.00219319 0.00218272 0.00216479 0.00216077\n",
      " 0.00213255 0.00212709 0.00212226 0.00211296 0.00209855 0.00208429\n",
      " 0.00207867 0.00205619 0.00204821 0.00203392 0.00203243 0.00202923\n",
      " 0.00201186 0.00200539 0.00198276 0.0019704  0.00196202 0.00195681\n",
      " 0.00194469 0.001932   0.00192108 0.0019188  0.00190889 0.001894\n",
      " 0.00187775 0.00187451 0.00185329 0.0018521  0.00184318 0.00182356\n",
      " 0.00181864 0.0018118  0.00181035 0.00180467 0.00178813 0.00177679\n",
      " 0.00177099 0.00176757 0.00175389 0.00175171 0.00173953 0.00173208\n",
      " 0.00172648 0.00170996 0.00170305 0.0016929  0.00168574 0.00167667\n",
      " 0.00166255 0.00166191 0.00165723 0.00164624 0.0016453  0.00163478\n",
      " 0.00162337 0.00160563 0.00160326 0.00160117 0.0015918  0.00157727\n",
      " 0.00157114 0.00156709 0.00156235 0.00156024 0.00155131 0.00153548\n",
      " 0.00152567 0.00152079 0.00151382 0.00150582 0.00149595 0.00148838\n",
      " 0.00148457 0.00147868 0.00146468 0.00146129 0.00145261 0.00144931\n",
      " 0.00143827 0.0014322  0.00142499 0.00141961 0.00141628 0.00140814\n",
      " 0.00139971 0.00138896 0.0013864  0.00137709 0.00136687 0.00136325\n",
      " 0.00135609 0.00134018 0.00133069 0.00131691 0.00131507 0.00130051\n",
      " 0.00129425 0.00129379 0.0012897  0.00127991 0.00127294]\n",
      "0.7363047956189979\n",
      "[8.07063682 3.23598626 3.07084294 2.84147022 2.56578981 2.51372174\n",
      " 2.44300402 2.35595553 2.29613156 2.26264974 2.22772887 2.19512402\n",
      " 2.16565958 2.15659367 2.11400087 2.06989268 2.06209792 2.03464353\n",
      " 2.00823005 1.99766253 1.96838879 1.9538057  1.9435558  1.93787602\n",
      " 1.8978445  1.88616858 1.88053851 1.86634967 1.84829357 1.84014633\n",
      " 1.83572263 1.81774012 1.80829779 1.80005121 1.77442645 1.77102095\n",
      " 1.75784509 1.74557094 1.73902451 1.72680509 1.71907202 1.71195207\n",
      " 1.69290476 1.68786157 1.68185314 1.67571203 1.66719735 1.6540995\n",
      " 1.64827598 1.63515216 1.62938951 1.62536065 1.61463897 1.59309847\n",
      " 1.58902244 1.5880791  1.57732739 1.57405506 1.56630023 1.56418367\n",
      " 1.55163433 1.5462835  1.53631447 1.52839668 1.52107174 1.51927139\n",
      " 1.51693384 1.50473179 1.50157514 1.48688681 1.48388871 1.47994361\n",
      " 1.47175471 1.46902185 1.46760292 1.46164704 1.45372107 1.45118121\n",
      " 1.44247225 1.4323942  1.42954197 1.4281478  1.42278559 1.41665691\n",
      " 1.41007196 1.40626144 1.40466829 1.3957499  1.38838686 1.38725019\n",
      " 1.38442694 1.38237236 1.37479829 1.37097749 1.36719699 1.35845541\n",
      " 1.35699402 1.35208768 1.3488172  1.33924071 1.33860495 1.33375589\n",
      " 1.33036578 1.32526509 1.32381506 1.32076709 1.31357735 1.30995706\n",
      " 1.30713944 1.302958   1.29859198 1.29627974 1.28970882 1.28748238\n",
      " 1.28582588 1.28366856 1.27763176 1.27352904 1.2725762  1.26945031\n",
      " 1.26378957 1.25816379 1.25355898 1.25196183 1.2497275  1.24481064\n",
      " 1.24103286 1.23596215 1.23230682 1.22947301 1.224874   1.22421815\n",
      " 1.21576766 1.21535835 1.2130568  1.21016933 1.20517669 1.20402966\n",
      " 1.19616746 1.19475957 1.19329599 1.19064503 1.18662249 1.18265143\n",
      " 1.18093565 1.17453895 1.17227193 1.16829271 1.16772613 1.16680605\n",
      " 1.1618008  1.15992971 1.15358799 1.14982425 1.14742419 1.14636975\n",
      " 1.14244573 1.13855784 1.13532995 1.13468764 1.131678   1.12737861\n",
      " 1.12255322 1.1214725  1.11513259 1.1147538  1.11207456 1.10617062\n",
      " 1.1046667  1.10257291 1.10212514 1.10038422 1.09535615 1.09181765\n",
      " 1.09004139 1.08902044 1.08477868 1.08428107 1.08039039 1.07801528\n",
      " 1.07625278 1.07108877 1.06892448 1.06583148 1.06350052 1.06062553\n",
      " 1.0561696  1.05598515 1.05444498 1.05105102 1.05066476 1.04733684\n",
      " 1.0438552  1.03815205 1.03715894 1.03655587 1.03349428 1.02882349\n",
      " 1.02683182 1.02550199 1.02381582 1.02314706 1.02029818 1.01497281\n",
      " 1.01173629 1.0101129  1.0078274  1.00525568 1.00185197 0.99934335\n",
      " 0.9980059  0.99604933 0.99159106 0.99014803 0.98720561 0.98608292\n",
      " 0.98237724 0.98030384 0.97786275 0.97592682 0.974794   0.9720053\n",
      " 0.96906222 0.96547913 0.96448816 0.96119989 0.95768629 0.95651077\n",
      " 0.95398793 0.94823433 0.94492648 0.9401884  0.93930867 0.93409351\n",
      " 0.93184184 0.93167599 0.93030306 0.92687965 0.92423136]\n",
      "(239, 1766)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.860\n",
      "Test set score: 0.738\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) #선택된 component를 이용하여 2,000개의 feature로부터 feature extract (dimension reduce)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (729, 1351)\n",
      "Test set dimension: (244, 1351)\n",
      "Train set score: 0.888\n",
      "Test set score: 0.758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train) #tfidf와 동일하게 max_feature를 제한하여 학습\n",
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) # 2000이 된 것을 확인\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
